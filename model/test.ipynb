{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4cbbd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec shape: torch.Size([32, 1, 4, 1056])\n",
      "input shape: torch.Size([32, 1, 4, 1056])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x1056 and 264x264)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m TimeMixerEncoder(signal_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1056\u001b[39m, num_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, token_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/ljq/miniconda3/envs/few_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ljq/miniconda3/envs/few_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/ljq/code/Ringdown_gap_filling/Proj/model/QTranTimeMixerMod.py:142\u001b[0m, in \u001b[0;36mTimeMixerEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Q变换\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m#q_output = self.qtransform(x)  # (batch_size, 2, freq_bins, time_steps//down_samp)\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m#混合\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m x\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# \u001b[39;00m\n",
      "File \u001b[0;32m/home/ljq/miniconda3/envs/few_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ljq/miniconda3/envs/few_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/ljq/miniconda3/envs/few_env/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x1056 and 264x264)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"/home/ljq/code/Ringdown_gap_filling/Proj/\")\n",
    "from model.QTranTimeMixerMod import *\n",
    "\n",
    "signal = torch.randn(16, 1056)  # 假设批量大小为16，信号长度为1056\n",
    "qt=QTransformModule()\n",
    "spec=qt(signal)\n",
    "print(f\"spec shape: {spec.shape}\")\n",
    "model = TimeMixerEncoder(signal_length=1056, num_token=32, token_dim=64)\n",
    "output = model(spec)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from config.config import Config\n",
    "import math\n",
    "\n",
    "\n",
    "#Embedding\n",
    "import torch\n",
    "import math\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class SinusoidalPositionEmbedding(nn.Module):\n",
    "    def __init__(self, num_token=Config.num_token_IMR, token_dim=Config.segment_length_IMR, embedding_dim=Config.EMBEDDING_dim):\n",
    "        super(SinusoidalPositionEmbedding, self).__init__()\n",
    "        self.num_token = num_token\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.token_dim = token_dim\n",
    "        \n",
    "        # 创建正弦位置嵌入矩阵\n",
    "        position = torch.arange(0, self.num_token, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.token_dim, 2).float() * (-math.log(10000.0) / self.token_dim))\n",
    "        \n",
    "        # 正弦和余弦函数的嵌入\n",
    "        pe = torch.zeros(self.num_token, self.token_dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # 将正弦位置嵌入注册为常量\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "        # 线性映射层，将正弦位置嵌入映射到 output_dim\n",
    "        self.linear = nn.Linear(self.token_dim, self.embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 的形状为 (batch_size, channels, num_token, embedding_dim)\n",
    "        batch_size, channels, num_token,token_dim = x.shape\n",
    "        \n",
    "        # 扩展位置嵌入的维度以适应输入\n",
    "        position_embeds = self.pe[:self.num_token, :].unsqueeze(0).unsqueeze(0)  # 形状 (1, 1, num_token, embedding_dim)\n",
    "        position_embeds = position_embeds.expand(batch_size, channels, -1, -1)  # 形状 (batch_size, channels, num_token, embedding_dim)\n",
    "        \n",
    "        # 线性映射位置嵌入\n",
    "        position_embeds = self.linear(position_embeds)  # 形状变为 (batch_size, channels, num_token, output_dim)\n",
    "        \n",
    "        return position_embeds\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, token_dim=Config.segment_length_IMR, embedding_dim=Config.EMBEDDING_dim):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.token_dim = token_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # 定义线性层，将 token_dim 映射到 embedding_dim\n",
    "        self.linear = nn.Linear(self.token_dim, self.embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x 的形状为 (batch_size, channels, num_token, token_dim)\n",
    "        # 我们对最后一维 (token_dim) 进行线性映射\n",
    "        x = self.linear(x)\n",
    "        # 返回形状为 (batch_size, channels, num_token, embedding_dim)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class ConvEmbeddingWithLinear(nn.Module):\n",
    "    def __init__(self, channels=Config.channels, conv_out_channels=Config.CEout_channels, kernel_size=Config.CEkernel_size, padding=Config.CEpadding, token_dim=Config.segment_length_IMR,embedding_dim=Config.EMBEDDING_dim):\n",
    "        super(ConvEmbeddingWithLinear, self).__init__()\n",
    "        self.channels=channels\n",
    "        self.token_dim = token_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # 定义 2D 卷积层\n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=conv_out_channels, kernel_size=kernel_size, padding=padding)\n",
    "        \n",
    "        # 定义线性映射层，映射到最终的 embedding_dim\n",
    "        self.linear = nn.Linear(self.token_dim, self.embedding_dim)\n",
    "        \n",
    "        # 激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 的形状为 (batch_size, channels, num_tokens, token_dim)\n",
    "        #print(f\"x shape after convolution: {x.shape}\")\n",
    "        # Step 1: 进行 2D 卷积，保持 channels 不变\n",
    "        conv_out = self.conv(x)  # 卷积输出的形状 (batch_size, channels, num_tokens, token_dim)\n",
    "        conv_out = self.relu(conv_out)\n",
    "        #print(f\"conv_out shape after convolution: {conv_out.shape}\")\n",
    "        # Step 2: 线性层映射，仅映射 token_dim\n",
    "        #batch_size, channels, num_tokens, token_dim = conv_out.shape\n",
    "        \n",
    "        # 将 token_dim 映射为 embedding_dim，形状为 (batch_size, channels, num_tokens, embedding_dim)\n",
    "        #conv_out = conv_out.view(batch_size * channels, num_tokens, token_dim)\n",
    "        embedding = self.linear(conv_out)  # 线性映射 token_dim -> embedding_dim\n",
    "        #print(f\"conv_out shape after convolution: {conv_out.shape}\")\n",
    "        # 将形状恢复为 (batch_size, channels, num_tokens, embedding_dim)\n",
    "        #embedding = embedding.view(batch_size, self.channels, num_tokens, -1)\n",
    "        \n",
    "        return embedding\n",
    "\n",
    "class ConditionMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=Config.EMBEDDING_dim):\n",
    "        super(ConditionMLP, self).__init__()\n",
    "        # 定义 MLP：输入维度为 input_dim，输出维度为 output_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, Config.segment_length_IMR),  # 第一个线性层，映射到128维\n",
    "            nn.ReLU(),                  # 激活函数\n",
    "            nn.Linear(Config.segment_length_IMR, output_dim)   # 映射到目标的 64 维\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "\n",
    "class ConditionConv1D(nn.Module):\n",
    "    def __init__(self, input_channels=1, output_channels=Config.num_token_IMR):\n",
    "        super(ConditionConv1D, self).__init__()\n",
    "        # 定义 1D 卷积层\n",
    "        # in_channels = 1 表示输入通道数为 1，out_channels = 32 表示输出通道数为 32\n",
    "        # kernel_size = 3 表示卷积核大小，padding = 1 确保输入输出的长度保持不变\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入 x 形状为 (batch_size, 64)\n",
    "        # 先扩展成 (batch_size, 1, 64) 以适应 Conv1d 输入格式\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # 通过 1D 卷积，将形状变为 (batch_size, 32, 64)\n",
    "        x = self.conv1d(x)\n",
    "\n",
    "        # 激活函数\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Conv2DEMbedding(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=Config.channels, token_dim=Config.segment_length_IMR, embedding_dim=Config.EMBEDDING_dim, kernel_size=Config.ConEkernel_size, padding=Config.ConEpadding):\n",
    "        super(Conv2DEMbedding, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.token_dim = token_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        # 定义 2D 卷积层\n",
    "        # Conv2d: in_channels=1, out_channels=8, kernel_size=3x3, padding=1 保持输入的空间维度不变\n",
    "        self.conv2d = nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels, kernel_size=self.kernel_size, padding=self.padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(self.token_dim, self.embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入 x 的形状为 (batch_size, 32, 64)\n",
    "        # 先通过 unsqueeze 添加维度，变为 (batch_size, 1, 32, 64)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # 通过 2D 卷积，变为 (batch_size, 8, 32, 64)\n",
    "        x = self.conv2d(x)\n",
    "\n",
    "        # 激活函数\n",
    "        x = self.relu(x)\n",
    "        x=self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class ConditionEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConditionEmbedding, self).__init__()\n",
    "        # 定义 1D 卷积层\n",
    "        self.mlp = ConditionConv1D()\n",
    "        # 定义 2D 卷积层\n",
    "        self.conv1d = ConditionConv1D()\n",
    "        self.conv2dembedding = Conv2DEMbedding()\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        x = self.conv1d(x)\n",
    "        x = self.conv2dembedding(x)\n",
    "\n",
    "        return x    \n",
    "class TotalEmbedding(nn.Module):\n",
    "    def __init__(self, token_dim=Config.segment_length_IMR, embedding_dim=Config.EMBEDDING_dim, conv_channels=Config.channels, conv_out_channels=Config.channels,num_token=Config.num_token_IMR,kernel_size=Config.CEkernel_size_IMR, dropout_p=Config.dropout):\n",
    "        super(TotalEmbedding, self).__init__()\n",
    "        self.token_dim = token_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.conv_channels = conv_channels\n",
    "        self.conv_out_channels = conv_out_channels\n",
    "        self.num_token = num_token\n",
    "        self.kernel_size = kernel_size\n",
    "       \n",
    "        self.dropout_p = dropout_p\n",
    "        # 初始化各个嵌入模块\n",
    "        self.token_embedding = TokenEmbedding(self.token_dim, self.embedding_dim)\n",
    "        self.conv_embedding = ConvEmbeddingWithLinear(self.conv_channels, self.conv_out_channels, embedding_dim=self.embedding_dim)\n",
    "        self.position_embedding = SinusoidalPositionEmbedding(self.num_token, self.embedding_dim)\n",
    "        #self.condition_embedding=ConditionEmbedding()\n",
    "        # 2D 卷积层，用于之后的卷积操作\n",
    "        self.conv2d = nn.Conv2d(in_channels=self.conv_channels, out_channels=self.conv_channels, kernel_size=self.kernel_size, padding=1)\n",
    "        \n",
    "        # 激活函数 GeLU\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算 Token Embedding, Convolutional Embedding, Position Embedding\n",
    "        token_embed = self.token_embedding(x)\n",
    "        conv_embed = self.conv_embedding(x)\n",
    "        position_embed = self.position_embedding(x)\n",
    "        #condition_embed=self.condition_embedding(x)\n",
    "       \n",
    "\n",
    "        # DF = TE + CE + PE\n",
    "        DF = token_embed + conv_embed + position_embed#+condition_embed\n",
    "        \n",
    "        # 进行 2D 卷积并加上残差连接\n",
    "        conv_out = self.conv2d(DF)  # 卷积操作\n",
    "        conv_out = self.gelu(conv_out)  # GeLU 激活\n",
    "        DF_with_conv = DF + conv_out  # 残差项\n",
    "        \n",
    "        # Dropout 操作\n",
    "        RF = self.dropout(DF_with_conv)\n",
    "        \n",
    "        return RF\n",
    "class TransformerEncoderLayerWithChannels(nn.Module):\n",
    "    def __init__(self, embedding_dim=Config.EMBEDDING_dim, num_heads=Config.num_heads, dim_feedforward=Config.FF_dim, dropout=Config.dropout):\n",
    "        super(TransformerEncoderLayerWithChannels, self).__init__()\n",
    "        self.embedding_dim = embedding_dim \n",
    "        self.num_heads = num_heads\n",
    "        self.dim_feedforward = dim_feedforward  \n",
    "        self.dropout = dropout\n",
    "        # 定义多头自注意力机制\n",
    "        # Multi-head Self-Attention\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=self.embedding_dim, num_heads=self.num_heads, dropout=self.dropout)\n",
    "        \n",
    "        # Feedforward Network\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.dim_feedforward, self.embedding_dim),\n",
    "        )\n",
    "        \n",
    "        # Layer Normalization\n",
    "        self.norm1 = nn.LayerNorm(self.embedding_dim)\n",
    "        self.norm2 = nn.LayerNorm(self.embedding_dim)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src 的形状为 (batch_size, channels, num_tokens, embedding_dim)\n",
    "        batch_size, channels, num_tokens, embedding_dim = src.shape\n",
    "        \n",
    "        # 我们对每个 channel 独立应用 self-attention\n",
    "        outputs = []\n",
    "        for ch in range(channels):\n",
    "            # 对于每个 channel，进行 multi-head self-attention\n",
    "            src_ch = src[:, ch, :, :]  # 取出当前 channel 的数据，形状为 (batch_size, num_tokens, embedding_dim)\n",
    "            \n",
    "            # Self-Attention expects input as (num_tokens, batch_size, embedding_dim)\n",
    "            src_ch_transposed = src_ch.transpose(0, 1)  # 转置为 (num_tokens, batch_size, embedding_dim)\n",
    "            \n",
    "            # Self-Attention, output shape: (num_tokens, batch_size, embedding_dim)\n",
    "            attn_output, _ = self.self_attn(src_ch_transposed, src_ch_transposed, src_ch_transposed)\n",
    "            \n",
    "            # Residual Connection + Layer Normalization\n",
    "            src2 = src_ch_transposed + self.dropout(attn_output)\n",
    "            src2 = self.norm1(src2)\n",
    "            \n",
    "            # Feedforward Layer\n",
    "            src2_transposed = src2.transpose(0, 1)  # 转回 (batch_size, num_tokens, embedding_dim)\n",
    "            feedforward_output = self.feedforward(src2_transposed)\n",
    "            \n",
    "            # Residual Connection + Layer Normalization\n",
    "            src3 = src2_transposed + self.dropout(feedforward_output)\n",
    "            output = self.norm2(src3)\n",
    "            \n",
    "            # 将处理好的 channel 加入 outputs 列表\n",
    "            outputs.append(output.unsqueeze(1))  # (batch_size, 1, num_tokens, embedding_dim)\n",
    "        \n",
    "        # 拼接所有 channels\n",
    "        outputs = torch.cat(outputs, dim=1)  # 最终形状为 (batch_size, channels, num_tokens, embedding_dim)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=Config.EMBEDDING_dim, num_heads=Config.num_heads, num_layers=Config.num_layers_T, dim_feedforward=Config.FF_dim, dropout=Config.dropout):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.dropout = dropout\n",
    "        self.layers = nn.ModuleList([TransformerEncoderLayerWithChannels(self.embedding_dim, self.num_heads, self.dim_feedforward, self.dropout) for _ in range(self.num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels=Config.channels, token_dim=Config.segment_length_IMR, embedding_dim=Config.EMBEDDING_dim, num_heads=Config.num_heads, num_layers=Config.num_layers_T, dropout=Config.dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.token_dim = token_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        # 初始化各个嵌入模块\n",
    "        #self.token_embedding = TokenEmbedding(token_dim, embedding_dim)\n",
    "        #self.conv_embedding = ConvEmbeddingWithLinear(channels, token_dim, embedding_dim=embedding_dim)\n",
    "        #self.position_embedding = SinusoidalPositionEmbedding(Config.num_token, token_dim, embedding_dim)\n",
    "        self.totalembedding=TotalEmbedding()\n",
    "        self.transformer = TransformerEncoder()\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 进行 Token Embedding, Convolutional Embedding 和 Position Embedding\n",
    "        RF=self.totalembedding(x)\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        output = self.transformer(RF)# (batch_size, channels, num_tokens, embedding_dim)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=Config.EMBEDDING_dim, hidden_dim=Config.h_dim_MLP, output_dim=Config.EMBEDDING_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        # 定义两层全连接层\n",
    "        # 两层全连接层\n",
    "        # print(input_dim)\n",
    "        # print(f\"input_dim: {input_dim}, type: {type(input_dim)}\")\n",
    "        # print(f\"hidden_dim: {hidden_dim}, type: {type(hidden_dim)}\")\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_dim, self.hidden_dim)  # 第一层\n",
    "        self.relu = nn.ReLU()  # 激活函数\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, self.output_dim)  # 第二层，将输出维度映射到 64\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 形状: (batch_size, channels, num_tokens, embedding_dim)\n",
    "        batch_size, channels, num_tokens, embedding_dim = x.shape\n",
    "\n",
    "        # 调整维度以适配全连接层\n",
    "        x = x.view(batch_size * channels * num_tokens, embedding_dim)  # 展平成 (batch_size * channels * num_tokens, embedding_dim)\n",
    "        x = self.fc1(x)  # 第一层全连接\n",
    "        x = self.relu(x)  # 激活函数\n",
    "        x = self.fc2(x)  # 第二层全连接，输出维度为 64\n",
    "\n",
    "        # 恢复形状为 (batch_size, channels, num_tokens, output_dim)\n",
    "        x = x.view(batch_size, channels, num_tokens, -1)\n",
    "        return x\n",
    "class InverseTokenEmbedding(nn.Module):\n",
    "    def __init__(self, token_embedding_layer):\n",
    "        super(InverseTokenEmbedding, self).__init__()\n",
    "        # 获取 TokenEmbedding 的权重并转置\n",
    "        weight = token_embedding_layer.linear.weight\n",
    "        self.inverse_linear = nn.Linear(weight.size(1), weight.size(0), bias=False)  # 定义逆映射层\n",
    "        self.inverse_linear.weight = nn.Parameter(weight.T)  # 使用转置后的权重\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.inverse_linear(x)\n",
    "def combine_segments(segments, segment_length=Config.segment_length_IMR, signal_length=Config.signal_length_IMR, overlap=Config.overlap):\n",
    "    \"\"\"\n",
    "    将分段的信号重新组合为原始信号，并处理重叠部分。\n",
    "    \n",
    "    参数:\n",
    "    - segments: 输入形状为 (batch_size, channels, num_segments, segment_length) 的张量\n",
    "    - segment_length: 每个分段的长度，默认为 64\n",
    "    - signal_length: 重组后的信号总长度，默认为 1056\n",
    "    - overlap: 重叠率，默认为 50%\n",
    "\n",
    "    返回:\n",
    "    - 重组后的信号，形状为 (batch_size, channels, signal_length)\n",
    "    \"\"\"\n",
    "    batch_size, channels, num_segments, _ = segments.shape\n",
    "    step_size = int(segment_length * (1 - overlap))  # 步长，重叠 50% 的话，步长是 segment_length 的一半\n",
    "\n",
    "    # 初始化输出张量，用于存储重新拼接后的信号\n",
    "    output = torch.zeros((batch_size, channels, signal_length), dtype=segments.dtype)\n",
    "\n",
    "    # 初始化一个计数器张量，用于记录每个位置被覆盖的次数\n",
    "    counter = torch.zeros((batch_size, channels, signal_length), dtype=segments.dtype)\n",
    "\n",
    "    # 将每个 segment 拼接到输出张量中\n",
    "    for i in range(num_segments):\n",
    "        start = i * step_size  # 计算每个分段的起始位置\n",
    "        end = start + segment_length\n",
    "        output=output.to(device)\n",
    "        segments=segments.to(device)\n",
    "        counter=counter.to(device)\n",
    "        # 将当前分段添加到输出张量\n",
    "        output[:, :, start:end] += segments[:, :, i, :]\n",
    "        \n",
    "        # 计数器记录每个位置被覆盖的次数\n",
    "        counter[:, :, start:end] += 1\n",
    "\n",
    "    # 处理重叠区域：将那些被多次覆盖的部分除以覆盖次数（即重叠部分除以 2）\n",
    "    output = output / counter\n",
    "\n",
    "    return output\n",
    "class ChannelMerger(nn.Module):\n",
    "    def __init__(self, input_channels=Config.channels, output_channels=1, signal_length=Config.signal_length_IMR):\n",
    "        super(ChannelMerger, self).__init__()\n",
    "        # 输入信号的通道数和输出信号的通道数\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.signal_length = signal_length\n",
    "        # 定义 Conv1d 卷积层，将输入 8 个通道的信号变换为 1 个输出信号\n",
    "        # kernel_size=3, padding=1 用于保持输入输出信号长度不变\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 输入的 x 形状为 (batch_size, input_channels=8, signal_length=1056)\n",
    "        # 通过 1D 卷积，将每个通道卷积成长度相同的信号\n",
    "        output = self.conv1d(x)\n",
    "        # 卷积的输出形状为 (batch_size, output_channels=1, signal_length=1056)\n",
    "        return output  # 将 (batch_size, 1, 1056) 变为 (batch_size, 1056)\n",
    "\n",
    "from ssqueezepy import icwt, Wavelet\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, inverse_token_embedding):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.mlp = MLP()  # MLP模块\n",
    "        self.inverse_token_embedding = inverse_token_embedding  # 逆 Token Embedding 模块\n",
    "        self.CM=ChannelMerger()\n",
    "    def forward(self, encoder_output):\n",
    "        \"\"\"\n",
    "        :param encoder_output: 从 Encoder 得到的输出, 形状为 (batch_size, channels, num_tokens, embedding_dim)\n",
    "                               即 (16, 8, 32, 128)\n",
    "        :return: 最终重建的信号, 形状为 (batch_size, 1, signal_length) 即 (16, 1, 1056)\n",
    "        \"\"\"\n",
    "        # Step 1: MLP 处理\n",
    "        x = self.mlp(encoder_output)  # MLP 输出形状为 (16, 8, 32, 128)\n",
    "\n",
    "        # Step 2: 通过逆 Token Embedding 将数据从 (16, 8, 32, 128) 转换为 (16, 8, 32, 64)\n",
    "        x = self.inverse_token_embedding(x)  # 逆 Token Embedding 输出形状为 (16, 8, 32, 64)\n",
    "\n",
    "        # Step 3: Segment 拼接，将分段信号重新组合成 (16, 8, 1056)\n",
    "        x = combine_segments(x, segment_length=Config.segment_length_IMR, signal_length=Config.signal_length_IMR, overlap=0.5)  # 拼接后形状为 (16, 8, 1056)\n",
    "\n",
    "        # Step 4: 将 8 个通道的信号重建为 1 个通道\n",
    "        x = self.CM(x)  # 小波逆变换后形状为 (16, 1, 1056)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class IMRGapsFiller(nn.Module):\n",
    "    def __init__(self, channels=Config.channels, token_dim=Config.segment_length_IMR, embedding_dim=Config.EMBEDDING_dim, num_heads=Config.num_heads, num_layers=Config.num_layers_T, dropout=Config.dropout):\n",
    "        super(IMRGapsFiller, self).__init__()\n",
    "        self.encoder = Encoder(channels, token_dim, embedding_dim, num_heads, num_layers, dropout)\n",
    "        token_embedding_instance = self.encoder.totalembedding.token_embedding\n",
    "        self.inverse_token_embedding = InverseTokenEmbedding(token_embedding_instance)\n",
    "\n",
    "        self.decoder = Decoder(self.inverse_token_embedding)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):  \n",
    "\n",
    "        encoder_output = self.encoder(x)\n",
    "        output = self.decoder(encoder_output)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "few_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
